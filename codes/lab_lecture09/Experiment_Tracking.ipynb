{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda\n",
    "\n",
    "In the notebook, we borrow the code from week 2 and use hyperopt to tune hyperparameters.\n",
    "\n",
    "we will have a quick recap on the ML Practice I:\n",
    "1. Reading in the Kaggle data and adding features\n",
    "2. Using a **`Pipeline`** for proper cross-validation\n",
    "3. Combining **`GridSearchCV`** with **`Pipeline`**\n",
    "\n",
    "The following are new items: \n",
    "\n",
    "4. Efficiently searching for tuning parameters using **`RandomizedSearchCV`**\n",
    "5. Advanced Hyperparameter tuning using **`Hyperopt`**\n",
    "6. Adding features to a document-term matrix (using SciPy)\n",
    "7. Adding features to a document-term matrix (using **`FeatureUnion`**)\n",
    "8. Ensembling models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Practice Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Python 2: use print only as a function\n",
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Reading in the Kaggle data and adding features\n",
    "\n",
    "- Our goal is to predict the **cuisine** of a recipe, given its **ingredients**.\n",
    "- **Feature engineering** is the process through which you create features that don't natively exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts a DataFrame and adds new features\n",
    "def make_features(df):  \n",
    "    # string representation of the ingredient list\n",
    "    df['ingredients_str'] = df.ingredients.astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the same features in the training data and the new data\n",
    "train = make_features(pd.read_json('../data/cuisine_data/train.json'))\n",
    "new = make_features(pd.read_json('../data/cuisine_data/test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>ingredients_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "      <td>['romaine lettuce', 'black olives', 'grape tom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "      <td>['plain flour', 'ground pepper', 'salt', 'toma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "      <td>['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "      <td>['water', 'vegetable oil', 'wheat', 'salt']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "      <td>['black pepper', 'shallots', 'cornflour', 'cay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients  \\\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...   \n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...   \n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...   \n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]   \n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe...   \n",
       "\n",
       "                                     ingredients_str  \n",
       "0  ['romaine lettuce', 'black olives', 'grape tom...  \n",
       "1  ['plain flour', 'ground pepper', 'salt', 'toma...  \n",
       "2  ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...  \n",
       "3        ['water', 'vegetable oil', 'wheat', 'salt']  \n",
       "4  ['black pepper', 'shallots', 'cornflour', 'cay...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Using a `Pipeline` for proper cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = train.ingredients_str\n",
    "y = train.cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    ['romaine lettuce', 'black olives', 'grape tom...\n",
       "1    ['plain flour', 'ground pepper', 'salt', 'toma...\n",
       "2    ['eggs', 'pepper', 'salt', 'mayonaise', 'cooki...\n",
       "3          ['water', 'vegetable oil', 'wheat', 'salt']\n",
       "4    ['black pepper', 'shallots', 'cornflour', 'cay...\n",
       "Name: ingredients_str, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is just a Series of strings\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the regex pattern that is used for tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer(token_pattern=r\"'([a-z ]+)'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and instantiate Multinomial Naive Bayes (with the default parameters)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[make_pipeline documentation](http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pipeline of vectorization and Naive Bayes\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe = make_pipeline(vect, nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('countvectorizer', CountVectorizer(token_pattern=\"'([a-z ]+)'\")),\n",
       " ('multinomialnb', MultinomialNB())]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the pipeline steps\n",
    "pipe.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proper cross-validation:**\n",
    "\n",
    "- By passing our pipeline to **`cross_val_score`**, features will be created from **`X`** (via **`CountVectorizer`**) within each fold of cross-validation.\n",
    "- This process simulates the real world, in which your out-of-sample data will contain **features that were not seen** during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323126392849393"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross-validate the entire pipeline\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "cross_val_score(pipe, X, y, cv=5, scoring='accuracy').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['countvectorizer', 'multinomialnb'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline steps are automatically assigned names by make_pipeline\n",
    "pipe.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Tuning Hyperparameters via Bayesian Optimization (using Hyperopt)\n",
    "\n",
    "- Different from grid-search and random-search, bayesian optimization aims to limit evals of the objective function by spending more time chossing the next value to try. \n",
    "- Define a probability model of P(loss|input parameters), which can be a surrogate function. \n",
    "- Select the next parameters values by applying a criteria (Expected Improvement) to the surrogate function.\n",
    "- Why we call it bayesian? Updating a model based on new evidence and the probability model is updated to incorporate the latest information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use pip from jupyter notebook to install package\n",
    "#!pip install seaborn\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from time import time\n",
    "\"\"\"\n",
    "all different parameter spaces should be joined in one tuple or dictionary. hyperpot define several spaces as:\n",
    "\n",
    "1. hp.choice(name_arguments, options):    label is a string input which refers to the hyperparameter\n",
    "                                 options will contain a list, one element will be returned from the list for that particular label.\n",
    "2. hp.uniform(label, low, high):  Again the label will contain the string referring to hyperparameter \n",
    "                                  and returns a value uniformly between low and high. \n",
    "                                  And when optimizing, this variable is constrained to a two-sided interval\n",
    "\n",
    "\"\"\"\n",
    "param_hyperopt= {\n",
    "    'countvectorizer__token_pattern': hp.choice('countvectorizer__token_pattern', [r\"\\b\\w\\w+\\b\", r\"'([a-z ]+)'\"]),\n",
    "    'countvectorizer__min_df':        hp.choice('countvectorizer__min_df', np.arange(1, 5,1, dtype=int)), \n",
    "    'multinomialnb__alpha':           hp.uniform('multinomialnb__alpha', 0.0, 1.0)                                   \n",
    "}\n",
    "hyparams_list = list(param_hyperopt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['countvectorizer__token_pattern',\n",
       " 'countvectorizer__min_df',\n",
       " 'multinomialnb__alpha']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(param_hyperopt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt(param_space, X_train, y_train, num_eval):\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    # defin the object function\n",
    "    def objective_function(params):\n",
    "        \"\"\"since pipe object is not callable, we can not use pipe(**params) \"\"\"\n",
    "        clf = pipe.set_params(**params) ### since pipelien object is not callable\n",
    "        score = cross_val_score(clf, X_train, y_train, cv=5).mean()\n",
    "        return {'loss': -score, 'status': STATUS_OK}\n",
    "\n",
    "    trials = Trials()\n",
    "    \"\"\"fmin function will iterate on differnt sets of algoritms and their hyperparmeters\n",
    "        and return the set on which loss is minimum.\n",
    "    \"\"\"\n",
    "    best_param = fmin(objective_function, \n",
    "                      param_space, \n",
    "                      algo=tpe.suggest, # you can change other algorithms such as GP,\n",
    "                      max_evals=num_eval, \n",
    "                      trials=trials,\n",
    "                      rstate= np.random.default_rng(42))\n",
    "    loss = [x['result']['loss'] for x in trials.trials]\n",
    "    \n",
    "    best_param_values = [x for x in best_param.values()]\n",
    "    \n",
    "    if best_param_values[0] == 0:\n",
    "        token_type = r\"\\b\\w\\w+\\b\"\n",
    "    else:\n",
    "        token_type = r\"'([a-z ]+)'\"\n",
    "    \n",
    "    clf_best = pipe.set_params(countvectorizer__token_pattern=token_type,\n",
    "                    countvectorizer__min_df=int(best_param_values[1]),\n",
    "                    multinomialnb__alpha=float(best_param_values[2]))\n",
    "                                  \n",
    "    clf_best.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"##### Results\")\n",
    "    print(\"Score best parameters: \", min(loss)*-1)\n",
    "    print(\"Best parameters: \", best_param)\n",
    "    print(\"Time elapsed: \", time() - start)\n",
    "    print(\"Parameter combinations evaluated: \", num_eval)\n",
    "    \n",
    "    return trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████| 5/5 [00:09<00:00,  1.90s/trial, best loss: -0.7476995552838627]\n",
      "\n",
      "##### Results\n",
      "Score best parameters:  0.7476995552838627\n",
      "Best parameters:  {'countvectorizer__min_df': 0, 'countvectorizer__token_pattern': 1, 'multinomialnb__alpha': 0.5029037546614818}\n",
      "Time elapsed:  9.95956826210022\n",
      "Parameter combinations evaluated:  5\n"
     ]
    }
   ],
   "source": [
    "results_hyperopt = hyperopt(param_hyperopt, X, y,num_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: MLflow is used to track\n",
    "\n",
    "- Different from grid-search and random-search, bayesian optimization aims to limit evals of the objective function by spending more time chossing the next value to try. \n",
    "- Define a probability model of P(loss|input parameters), which can be a surrogate function. \n",
    "- Select the next parameters values by applying a criteria (Expected Improvement) to the surrogate function.\n",
    "- Why we call it bayesian? Updating a model based on new evidence and the probability model is updated to incorporate the latest information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the command  \n",
    "\n",
    "```console\n",
    "mlflow server --backend-store-uri sqlite:///mydb.sqlite\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "RANDOM_SEED = 0\n",
    "\n",
    "mlflow.set_tracking_uri('http://0.0.0.0:5000')\n",
    "\n",
    "try:\n",
    "    EXPERIMENT_ID = mlflow.create_experiment('sklearn-pipeline-hyperopt')\n",
    "except:\n",
    "    EXPERIMENT_ID = dict(mlflow.get_experiment_by_name('sklearn-pipeline-hyperopt'))['experiment_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 6/6 [02:04<00:00, 20.76s/trial, best loss: -0.75]\n"
     ]
    }
   ],
   "source": [
    "def train_model(params):\n",
    "    \n",
    "    # enable autologging\n",
    "    #mlflow.sklearn.autolog()\n",
    "    \n",
    "    with mlflow.start_run(experiment_id=EXPERIMENT_ID, nested=True):\n",
    "        metric_names = ['accuracy', 'f1_micro']        \n",
    "        clf = pipe.set_params(**params) ### since pipelien object is not callable\n",
    "        scores = cross_validate(clf, X, y, \n",
    "                                cv=5, scoring=metric_names, return_train_score=True)        \n",
    "        training_metrics = {\n",
    "            'Accuracy': scores['train_accuracy'].mean().round(3),\n",
    "            'F1': scores['train_f1_micro'].mean().round(3)\n",
    "        }\n",
    "        training_metrics_values = list(training_metrics.values())\n",
    "\n",
    "        validation_metrics = {\n",
    "            'Accuracy': scores['test_accuracy'].mean().round(3),\n",
    "            'F1': scores['test_f1_micro'].mean().round(3)\n",
    "        }\n",
    "        validation_metrics_values = list(validation_metrics.values())\n",
    "        \n",
    "        # Logging model signature, class, and name\n",
    "        #signature = infer_signature(X_train, y_val_pred)\n",
    "        mlflow.sklearn.log_model(clf, 'model')\n",
    "        #mlflow.set_tag('estimator_name', model.__class__.__name__)\n",
    "        \n",
    "        # Logging each metric\n",
    "        for name, metric in list(zip(metric_names, training_metrics_values)):\n",
    "            mlflow.log_metric(f'training_{name}', metric)\n",
    "        for name, metric in list(zip(metric_names, validation_metrics_values)):\n",
    "            mlflow.log_metric(f'validation_{name}', metric)\n",
    "        \n",
    "        # Logging each hyper-parameters\n",
    "        for name in hyparams_list:\n",
    "            mlflow.log_param(name, params[name])\n",
    "\n",
    "        # Set the loss to -1*F1 so fmin maximizes the it\n",
    "        return {'loss': -1*validation_metrics['F1'], 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "\"\"\"fmin function will iterate on differnt sets of algoritms and their hyperparmeters\n",
    "        and return the set on which loss is minimum.\n",
    "\"\"\"\n",
    "# Run fmin within an MLflow run context so that each hyperparameter configuration is logged as a child run of a parent\n",
    "# run called \"sklearn_pipeline\" .\n",
    "with mlflow.start_run(experiment_id=EXPERIMENT_ID, run_name='sklearn_pipe'):\n",
    "    xgboost_best_params = fmin(\n",
    "        fn=train_model, \n",
    "        space=param_hyperopt, \n",
    "        algo=tpe.suggest,\n",
    "        trials=trials,\n",
    "        max_evals=6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(EXPERIMENT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
